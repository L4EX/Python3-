{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单线性回归的目标是，找到a和b，使得\n",
    "$\\sum_i \\left( \\widehat{y}^{(i)} - y^{(i)}\\right)^2$\n",
    "的结果最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "多元线性回归的目标函数和简单线性回归的一样  \n",
    "区别在于$ \\widehat{y}^{(i)} = \\theta_0 + \\theta_1X^{(i)}_1 + \\theta_2X^{(i)}_2 + ... + \\theta_nX^{(i)}_n $\n",
    "所以多元线性回归的目标是，找到$\\theta_0,\\theta_1,\\theta_2,...,\\theta_n$使得$\\sum_i \\left( \\widehat{y}^{(i)} - y^{(i)}\\right)^2$\n",
    "的结果最小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将$ \\theta$写成向量的形式： $\\theta = (\\theta_0,\\theta_1,\\theta_2,...,\\theta_n)^T$  \n",
    "为了将X也统一成和$ \\theta$元素个数相同的向量，将X扩展一个特征$X^{(i)}_0$，$X^{(i)}_0$恒为1 \n",
    "也就是能够写作 $ \\widehat{y}^{(i)} = \\theta_0X^{(i)}_0 + \\theta_1X^{(i)}_1 + \\theta_2X^{(i)}_2 + ... + \\theta_nX^{(i)}_n $  \n",
    "此时， $X^{(i)}=(X^{(i)}_0,X^{(i)}_1,X^{(i)}_2,...,X^{(i)}_n)   $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样做的好处是，凑成了两个向量对应元素相乘再相加的形式，满足了向量化运算的条件，可以使用高效的向量化运算  \n",
    "$ \\widehat{y}^{(i)} = X^{(i)}·\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以目标函数变成：  \n",
    "$\\sum_i \\left( {y}^{(i)} -X^{(i)}·\\theta\\right)^2$  \n",
    "这又是一个对应元素相乘再相加的形式。  \n",
    "所以可以写成  \n",
    "$\\left( {y} -X·\\theta\\right) · \\left( {y} -X·\\theta\\right)$  \n",
    "考虑到$\\left( \\widehat{y} -X·\\theta\\right)$是个列向量，按照矩阵运算规则，应该写成  \n",
    "$\\left( {y} -X·\\theta\\right)^T · \\left( {y} -X·\\theta\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个$X$已经做过修改，为了区别，定义$X_b$  \n",
    "$X_b=\\begin{bmatrix} 1 & x^{(1)}_{1} & x^{(1)}_{2} & ... & x^{(1)}_{n} \\\\ 1 & x^{(2)}_{1} & x^{(2)}_{2} & ... & x^{(2)}_{n}\\\\...\\\\ 1 & x^{(m)}_{1} & x^{(m)}_{2} & ... & x^{(m)}_{n} \\end{bmatrix}\n",
    "\\qquad\n",
    "\\theta = \\begin{bmatrix} \\theta_0 \\\\ \\theta_1 \\\\ \\theta_2 \\\\ ... \\\\ \\theta_n \\end{bmatrix} $  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终有 $ \\widehat{y} = X_{b}·\\theta$\n",
    "$\\ \\ \\ $\n",
    "$ \\widehat{y}$是列向量，是X中每一个样本根据$\\theta$得到的预测值组成的向量。\n",
    "最终的目标函数写作：$\\left( {y} -X_b·\\theta\\right)^T · \\left( {y} -X_b·\\theta\\right)$  \n",
    "多元线性回归的目标变成：得到一个$\\theta$，使得$\\left( {y} -X_b·\\theta\\right)^T · \\left( {y} -X_b·\\theta\\right)$尽可能小"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据矩阵求导的运算法则，得到$\\theta = (X^T_bX_b)^{-1}X^T_by$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按这个公式称为多元线性回归的正规方程解(Normal Equation)，直接用数学表达式就可以求出参数的解，很少见  \n",
    "缺点：时间复杂度高——O(n^3), n不区分是行数还是列数，优化后可达到O(n^2.4)  \n",
    "优点：不需要对数据进行归一化处理，因为不涉及量纲问题，直接计算就行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
